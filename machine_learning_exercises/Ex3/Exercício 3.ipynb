{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "__177312 - Tales lelo da Aparecida__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Leia o arquivo *abalone* do exercício 2.  \n",
    "Faça o preprocessamento do atributo categórico e do atributo de saída como no exercício 2 estandardize todos os atributos numéricos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeiras 5 linhas:\n",
      "        1      2      3      4      5      6      7      F      I      M  >13y\n",
      "0 -0.575 -0.432 -1.064 -0.642 -0.608 -0.726 -0.638 -0.675 -0.688  1.317     1\n",
      "1 -1.449 -1.440 -1.184 -1.230 -1.171 -1.205 -1.213 -0.675 -0.688  1.317     0\n",
      "2  0.050  0.122 -0.108 -0.309 -0.463 -0.357 -0.207  1.482 -0.688 -0.759     0\n",
      "3 -0.699 -0.432 -0.347 -0.638 -0.648 -0.608 -0.602 -0.675 -0.688  1.317     0\n",
      "4 -1.616 -1.541 -1.423 -1.272 -1.216 -1.287 -1.321 -0.675  1.453 -0.759     0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing         import scale\n",
    "from sklearn.linear_model          import LogisticRegression\n",
    "from sklearn.model_selection       import StratifiedKFold, GridSearchCV\n",
    "from sklearn.svm                   import LinearSVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "# Carrega um DataFrame com os dados do arquivo\n",
    "df = pd.io.parsers.read_csv('abalone.csv', ',', header=None )\n",
    "\n",
    "# Converte a 1ª coluna para um dado numérico\n",
    "df = pd.get_dummies(df, columns=[0])\n",
    "\n",
    "# Cria um DataFrame com a versão categórica (1:x>13, 0:x<=13) da coluna 8\n",
    "greaterThan13y = df.apply(lambda row: int(row[8]>13), 1)\n",
    "# Remove-a\n",
    "del df[8]\n",
    "\n",
    "# Estandardiza os dados\n",
    "x = scale(df.values)\n",
    "y = greaterThan13y.values\n",
    "\n",
    "# Separando dados para treino e teste\n",
    "x_train, y_train = x[:3133], y[:3133]\n",
    "x_test, y_test = x[3133:], y[3133:]\n",
    "\n",
    "# Renomeia as colunas para facilitar o acompanhamento\n",
    "df = pd.DataFrame(data=x[:5], columns=['1', '2', '3', '4', '5', '6', '7', 'F', 'I', 'M'])\n",
    "df['>13y'] = greaterThan13y\n",
    "\n",
    "# Mostra as primeiras linhas de nossos dados, para um preview de como estão até então\n",
    "pd.options.display.float_format = '{:,.3f}'.format\n",
    "print(\"Primeiras 5 linhas:\\n\", df[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Logistic regression\n",
    "Faça o logistic regression com $C=10^{-1,0,1,2,3}$. O loop externo deve ser um 5-fold CV estratificado. O loop interno para a escolha do hiperparâmetro deve ser um 3-fold estratificado.\n",
    "Voce tem que fazer o loop interno explicitamente, usando StratifiedKFold e não funções como GridSearchCV\n",
    "qual a acurácia do LR com a melhore escolha de parâmetros (para cada fold)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia para C =  10.0: 0.885167464115\n",
      "Acurácia para C = 100.0: 0.904306220096\n",
      "Acurácia para C =  10.0: 0.891547049442\n",
      "Acurácia para C =   1.0: 0.899521531100\n",
      "Acurácia para C =   1.0: 0.897600000000\n",
      "Acurácia do LogisticRegression: 0.895628452951\n"
     ]
    }
   ],
   "source": [
    "# Retorna duas listas com os índices gerados pelo kfold estratificado\n",
    "def getStratifiedKFoldArrays(k, x, y):\n",
    "    indexes_pairs = list(StratifiedKFold(k).split(x, y))\n",
    "    train_indexes, test_indexes = [], []\n",
    "    for i in range(k):\n",
    "        train_indexes.append(indexes_pairs[i][0])\n",
    "        test_indexes.append(indexes_pairs[i][1])\n",
    "    return train_indexes, test_indexes\n",
    "\n",
    "\n",
    "# Possíveis hiperparâmetros\n",
    "Cs = [1e-1, 1, 1e+1, 1e+2, 1e+3]\n",
    "\n",
    "# Gera os índices dos 5 folds (kfold estratificado)\n",
    "tr_5kf_idxs, ts_5kf_idxs = getStratifiedKFoldArrays(5, x_train, y_train)\n",
    "\n",
    "avg_log_score = 0\n",
    "for tr_5kf_idx, ts_5kf_idx in zip(tr_5kf_idxs, ts_5kf_idxs):\n",
    "    # Define os subvetores x e y, para treino e teste (5-kfold)\n",
    "    x_5kf_tr, y_5kf_tr = x_train[tr_5kf_idx], y_train[tr_5kf_idx] # Treino\n",
    "    x_5kf_ts, y_5kf_ts = x_train[ts_5kf_idx], y_train[ts_5kf_idx] # Teste\n",
    "\n",
    "    # Gera os indices dos 3 folds (kfold estratificado)\n",
    "    # Vale destacar que estes índices são relativos a x_train e y_train\n",
    "    tr_3kf_idxs, ts_3kf_idxs = getStratifiedKFoldArrays(3, x_5kf_tr, y_5kf_tr)\n",
    "    \n",
    "    # Loop verificador do melhor hiperparâmetro para o fold atual (5-kfold)\n",
    "    bestC, bestC_score = Cs[0], 0\n",
    "    for C in Cs:\n",
    "        avg_C_score = 0\n",
    "        for tr_3kf_idx, ts_3kf_idx in zip(tr_3kf_idxs, ts_3kf_idxs):\n",
    "            # Define os subvetores x e y, para treino e teste (3-kfold)\n",
    "            x_3kf_tr, y_3kf_tr = x_train[tr_3kf_idx], y_train[tr_3kf_idx] # Treino\n",
    "            x_3kf_ts, y_3kf_ts = x_train[ts_3kf_idx], y_train[ts_3kf_idx] # Teste\n",
    "            \n",
    "            # Treina e calcula a acurácia de C para o fold atual (3-kfold)\n",
    "            avg_C_score += LogisticRegression(C=C).fit(x_3kf_tr, y_3kf_tr).score(x_3kf_ts, y_3kf_ts)\n",
    "            \n",
    "        # Calcula a média da acurácia dos 3 folds\n",
    "        avg_C_score /= 3\n",
    "        \n",
    "        if (avg_C_score > bestC_score):\n",
    "            bestC, bestC_score = C, avg_C_score\n",
    "            \n",
    "    # Guarda a acurácia do LogisticRegression para o melhor C do fold atual\n",
    "    log_score = LogisticRegression(C=bestC).fit(x_5kf_tr, y_5kf_tr).score(x_5kf_ts, y_5kf_ts)\n",
    "    print('Acurácia para C = {:5.1f}: {:.12f}'.format(bestC, log_score))\n",
    "    avg_log_score += log_score\n",
    "    \n",
    "avg_log_score /= 5\n",
    "print(\"Acurácia do LogisticRegression:\", avg_log_score)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Linear SVM\n",
    "Faça o LinearSVM com $C=10^{-1,0,1,2,3}$. O loop externo deve ser um 5-fold estratificado. O loop interno um 3-fold estratificado. Neste caso voce não precisa fazer o 3 fold explicitamente, voce pode usar o GridSearchCV. Qual a acurácia do LinearSVM com a melhor escolha de C?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia para C = 10.0: 0.888357256778\n",
      "Acurácia para C =  0.1: 0.894736842105\n",
      "Acurácia para C =  1.0: 0.889952153110\n",
      "Acurácia para C =  0.1: 0.904306220096\n",
      "Acurácia para C =  0.1: 0.892800000000\n",
      "Acurácia do LinearSVM : 0.894030494418\n"
     ]
    }
   ],
   "source": [
    "avg_svc_score = 0\n",
    "for tr_5kf_idx, ts_5kf_idx in zip(tr_5kf_idxs, ts_5kf_idxs):\n",
    "    # Define os subvetores x e y, para treino e teste (5-kfold)\n",
    "    x_5kf_tr, y_5kf_tr = x_train[tr_5kf_idx], y_train[tr_5kf_idx] # Treino\n",
    "    x_5kf_ts, y_5kf_ts = x_train[ts_5kf_idx], y_train[ts_5kf_idx] # Teste\n",
    "    \n",
    "    # Procura o melhor C com 3 folds (StratifiedKFold)\n",
    "    gscv = GridSearchCV(LinearSVC(), {'C':Cs}).fit(x_5kf_tr, y_5kf_tr)\n",
    "    \n",
    "    # Guarda a acurácia do LinearSVC para o melhor C do fold atual\n",
    "    svc_score = gscv.score(x_5kf_ts, y_5kf_ts)\n",
    "    print('Acurácia para C = {:4.1f}: {:.12f}'.format(gscv.best_params_[\"C\"], svc_score))\n",
    "    avg_svc_score += svc_score\n",
    "    \n",
    "avg_svc_score /= 5\n",
    "print(\"Acurácia do LinearSVM :\", avg_svc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# LDA\n",
    "Faça o LDA. Reporte a acurácia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do LDA: 0.894636015326\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "lda_score = LDA().fit(x_train, y_train).score(x_test, y_test)\n",
    "print(\"Acurácia do LDA:\", lda_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Classificador final\n",
    "Qual o melhor classificador para esse problema?\n",
    "Se não o LDA, calcule o hiperparâmetro C a ser usado. Gere o classificador final.\n",
    "\n",
    "LR=0.895628452951 > LDA=0.894636015326 > SVM=0.894030494418  \n",
    "Ou seja, o **LogisticRegression** foi o melhor classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=10.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "# Gera os indices dos 3 folds (kfold estratificado)\n",
    "tr_3kf_idxs, ts_3kf_idxs = getStratifiedKFoldArrays(3, x, y)\n",
    "\n",
    "# Loop verificador do melhor hiperparâmetro para o dados de treino\n",
    "bestC, bestC_score = Cs[0], 0\n",
    "for C in Cs:\n",
    "    avg_C_score = 0\n",
    "    for tr_3kf_idx, ts_3kf_idx in zip(tr_3kf_idxs, ts_3kf_idxs):\n",
    "        # Define os subvetores x e y, para treino e teste (3-kfold)\n",
    "        x_3kf_tr, y_3kf_tr = x[tr_3kf_idx], y[tr_3kf_idx] # Treino\n",
    "        x_3kf_ts, y_3kf_ts = x[ts_3kf_idx], y[ts_3kf_idx] # Teste\n",
    "\n",
    "        # Treina e calcula a acurácia de C para o fold atual (3-kfold)\n",
    "        avg_C_score += LogisticRegression(C=C).fit(x_3kf_tr, y_3kf_tr).score(x_3kf_ts, y_3kf_ts)\n",
    "\n",
    "    # Calcula a média da acurácia dos 3 folds\n",
    "    avg_C_score /= 3\n",
    "\n",
    "    if (avg_C_score > bestC_score):\n",
    "        bestC, bestC_score = C, avg_C_score\n",
    "\n",
    "print(LogisticRegression(C=bestC).fit(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este seria o classificador final, exibido sem pontuação, já que sabemos que o já escolhemos tanto o melhor algoritmo quanto seu melhor hiperparâmetro, podendo, assim, usar todos nossos dados para treino."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
